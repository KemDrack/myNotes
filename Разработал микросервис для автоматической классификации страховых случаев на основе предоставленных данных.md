
Соответственно клиент отправлял данные и мне их нужно было обработать, чтобы автоматически классифицировать страховой случай, классифицировал по ключевым словам и возвращал категории происшествия. Далее сохранял данные в MongoDB. 



Входящий запрос в **микросервис** мог содержать:
- **Описание страхового случая** – текст от клиента, в котором он описывает произошедшее (например, "Попал в ДТП, машина разбита, виновник скрылся").
- **Категория полиса** – какой именно страховой полис у клиента (автострахование, здоровье, имущество и т. д.).
- Дата и время происшествия
- Геолокация или адрес
- Фотографии или документы -> MongoDB
- Тип инцидента

Пример POST-запроса к микросервису:
```json
{
  "description": "Попал в ДТП, машина разбита, виновник скрылся",
  "policy_type": "auto",
  "incident_date": "2024-01-25T14:30:00Z",
  "location": "Москва, Тверская улица, 15",
  "attachments": [
    {
      "type": "image",
      "url": "https://example.com/damage_photo1.jpg"
    },
    {
      "type": "pdf",
      "url": "https://example.com/report.pdf"
    }
  ]
}
```
**Классификация страхового случая**
- По собранным данным определяешь тип страхового случая и уровень риска.
```go
func classifyClaim(description string, policyType string) string {
    if strings.Contains(description, "ДТП") || strings.Contains(description, "авария") {
        return "автострахование"
    }
    if strings.Contains(description, "кража") || strings.Contains(description, "ограбление") {
        return "имущество"
    }
    return "другие случаи"
}
```
**Сохранение результатов**
- После классификации ты мог **сохранить случай в MongoDB**:
```go
type InsuranceCase struct {
    ID           primitive.ObjectID `bson:"_id,omitempty"`
    Description  string             `bson:"description"`
    Category     string             `bson:"category"`
    Attachments  []string           `bson:"attachments"`
    CreatedAt    time.Time          `bson:"created_at"`
}
```
**Передача данных в Kafka**
```go
event := map[string]interface{}{
    "case_id":   caseID,
    "category":  classifiedCategory,
    "status":    "classified",
}
kafkaProducer.Produce("insurance_cases", event)
```
**Ответ клиенту**
```json
{
  "case_id": "654c4e2f9b1d7b0001a2c3d4",
  "category": "автострахование",
  "status": "classified"
}
```

### **Как использовал Redis и Kafka в микросервисе классификации страховых случаев**

- **Redis** — для повторяющихся категорий страховых случаев
Сначала проверял в Redis, есть ли уже готовая классификация для данного текста


**Kafka** – использовалась для интеграции с другими микросервисами. Микросервис занимался только классификацией, а остальные сервисы (уведомления, принятие решений) могли обрабатывать событие асинхронно