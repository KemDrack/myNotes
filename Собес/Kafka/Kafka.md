[[Вопросы с собеседований(Kafka)]]
[[Коротко про Kafka]]

**Zookeeper** - обеспечивает согласованность кластера

Распределенный брокер сообщений в стриминговом режиме(реальном времени), нам прилетает много сообщений, которые мы должны обработать и кому-то передать

Брокеры сообщений передают какие-то небольшие **сообщения по типу**:
Пользователь хх **оформил** подписку, пользователь хх **опубликовал** видео

Она идеально подходит для:
**Централизирования логов**: Сбор логов с множества серверов в одном месте
**Интеграция микросервисов**: Передача сообщений между сервисами(асинхронно) с высокой надёжностью.
**Обработка больших данных**: например, действий пользователей на сайте.

Продюсерам нужно знать только API брокера и Консьюмерам соответственно тоже. Между собой они никак не контактируют


**Плюсы** в сравнении с точка-точка
- Мы можем подстмотреть какие сообщения были отданы и обмен становится более контролируемым, какую то ретроспективу этих сообщений можно провести, опять же там с ньюансами, если поднастроить кафку, чтобы сообщения хранились достаточное кол-во времени до инцидента(по умолчанию вроде 7 дней)
**Минусы**
- Брокер может быть недоступен или ошибки с сетью
## Основные **компоненты** архитектуры **Kafka**:

**Брокер** — это сервер, который принимает, хранит и отправляет сообщения. Kafka-кластер состоит из нескольких брокеров, обеспечивающих отказоустойчивость и масштабирование.
- **Хранение данных**: Брокеры сохраняют данные на диске, что позволяет обрабатывать большие объёмы информации
- **Распределённость**: Сообщения распределяются между несколькими брокерами для равномерной нагрузки.
- **Репликация**: Для повышения надёжности сообщения копируются на другие брокеры.

Среди Брокеров выделяется один **спец.брокер(Kafka Controller)**. Он обеспечивает консистентность данных 


**Топик** — это логическая структура для группировки сообщений. Каждый топик может быть разделён на несколько партиций. В топике содержиться очередь, в которую складываются все входящие наши сообщения. Сообщения извлекаются **метом FIFO** (First-In-First-Out)
**Особенности**:
- Данные в топике хранятся в Log-файлах
- Сообщения сохраняются в топиках определённое время (например, 7 дней). Удаление по **TTL**(time-to-live). Удаляется сегмент партиции полностью
- Консюмеры могут читать сообщения из топика в любое время, независимо от других.


**Партиции** — это физические подразделения топика, которые помогают распараллелить нагрузку, ведь у нас BigData, HighLoad :) 
- Это конфигурируемый параметр, который мы задаем
- Если мы все считываем данные из **топика**, то значения у нас **неупорядоченные**, а если из определенной партиции то упорядоченность гарантируется

Партиции распределяются между **брокерами**, что позволяет обрабатывать большой объём данных, но возможно **несбалансированность** размещения партиций топика в автоматическом режиме
- Если у нас один топик очень жирный, а все остальные очень маленькие, то у нас может получиться, что партиции жирного топика лежат на одном брокере, на него будет очень большая нагрузка. Поэтому задачу балансировки приходиться иногда решать в ручном режиме: например у нас топик толстый и его партиции нужно распределить между брокерами

**Zookeeper** - координатор, в котором мы храним конфигурацию и состояние кластера. В новых версиях Kafka можно использовать **KRaft**, чтобы обойтись без Zookeeper

## Взаимодействие продюсеров и консюмеров

**Продюсер** — это компонент, который отправляет данные в Kafka. Его ключевые функции:
- **Выбор партиции**: Данные могут быть направлены в определённую партицию (по ключу), если мы будем отправлять одно и тоже сообщение, то оно будет попадать в одну партицию(Берем от ключа hash и берем остаток от деления на кол-во партиций) или распределены **случайным** образом
- **Подтверждения** (acks): Продюсер может ждать подтверждения от одного, нескольких или всех брокеров. (acks=0 -> Продюсер не ждет подтверждение отправки сообщений к брокеру(самый ненадеждый режим, какие то сообщения могут пропасть); acks=1 -> Продюсеру нужно подтверждение только от Leader реплики(Проблема может быть в том, что Leader не успеет скинуть синхронно данные Фоловерам ); acks= -1(ALL) -> Продюсер ждет подтверждение отправки сообщений от всех ISR-реплик, включая Leader)
- **Ретраи**: При временных сбоях продюсер может повторно отправить данные

**Консюмер** — это клиент, который читает (Только из Leader партиции) данные из топиков Kafka. Мы pollim не одно сообщение, а сразу пачку(из партиции)
Основные принципы работы:
- **Группы консюмеров**: Консюмеры объединяются в группы, где каждая партиция назначается одному консюмеру. Теперь каждый консюмер читает какие-то определенные партиции(4 консьюмера и 4 партиции)
- **Оффсеты**: Консюмеры отслеживают, какие сообщения уже были обработаны, с помощью оффсетов. (оффсеты хранятся в системном топике). **Пример**: первый Консюмер получил 0,1,2 сообщения и упал, то другой Консюмер возьмет на себя передачу оставшихся сообщений, но уже не включая те, которые передал упавший Консюмер
 -consumer-offsets
- **Подтверждение** (commit): Консюмер сообщает брокеру, что сообщение успешно обработано, чтобы избежать повторного чтения
*Гарантии доставки*<u></u>
**auto commit**(at most once), он не всегда хорош. Потому что когда мы получаем батч данных от брокера, то сразу происходит auto commit и Kafka считает, что для этой группы Консьюмеров эти сообщения уже обработаны, хотя Консьюмер их только получил и ему надо их обработать и если он в этот момент упал, то по сути он получил данные, но ничего с ними не сделал. Получается он потеряет сообщения, потому что при повторном подключении он пойдет уже со следующего offset

**manual commit**(at least once), когда Kafka нам предоставляет данные, сразу auto commit не происходит, мы обрабатываем данные и после того как мы обработали мы уже отправляем **commit** этого **offset**
Возможны дубли, **пример**: мы взяли 3 сообщения, первые 2 обработали и упали, commit не было, но при этом первые 2 мы обработали, тогда после перезапуска мы снова прочитаем эти 3 сообщения и нам нужно разбираться, мы первые 2 уже обработали или нет

**Exactly once:**
- Сообщение доставляется ровно один раз
- Подходит для финансовых транзакций или аналитики, где важна точность

## Сравнение Kafka и [[RabbitMQ]]

Хотя Kafka и RabbitMQ обе являются системами обмена сообщениями, у них разные области применения.

| **Характеристика**      | **Kafka**                                     | **RabbitMQ**                                |
| ----------------------- | --------------------------------------------- | ------------------------------------------- |
| **Архитектура**         | Распределённая система с хранением сообщений. | Централизованная система с маршрутизацией.  |
| **Модели доставки**     | At most once, at least once, exactly once.    | At most once, at least once.                |
| **Скорость обработки**  | Подходит для больших объёмов данных.          | Лучше для задач с меньшими объёмами данных. |
| **Упорядоченность**     | Гарантируется в пределах партиции.            | Гарантируется в пределах очереди.           |
| **Типы очередей**       | Потоковая обработка.                          | Сложная маршрутизация и обработка задач.    |
| **Основное назначение** | Аналитика, логирование, микросервисы.         | Очереди задач, RPC, микросервисы.           |

Соообщения в RabbitMQ не хранятся, а в Kafka могут храниться сколько мы им скажем
Используются разные модели передачи данных, у Kafka это модель pull, а у Rabbit push

## [[Пример взаимодействия микросервисов через Kafka]]: Сервис обработки заказов

#### **Описание задачи:**

1. **Сервис заказов (Order Service):**
    
    - Получает заказы от клиентов.
    - Сохраняет их в базу данных.
    - Передаёт информацию о заказе в Kafka, чтобы другие сервисы могли обработать заказ.
2. **Сервис оплаты (Payment Service):**
    
    - Получает уведомление о новом заказе через Kafka.
    - Проводит оплату и обновляет статус заказа.
3. **Сервис уведомлений (Notification Service):**
    
    - Получает уведомление об успешной оплате.
    - Отправляет клиенту сообщение о подтверждении заказа.

- **Order Service** → Отправляет сообщение в Kafka о новом заказе.
- **Payment Service** → Читает из Kafka, обрабатывает оплату и отправляет результат обратно в Kafka.
- **Notification Service** → Читает из Kafka и отправляет уведомление клиенту.
## Преимущества использования Kafka

- **Высокая пропускная способность**: Kafka может обрабатывать миллионы сообщений в секунду.
- **Горизонтальное масштабирование**: Партиции позволяют равномерно распределить нагрузку.
- **Надёжность**: Данные реплицируются между брокерами для обеспечения отказоустойчивости.
- **Гибкость**: Используется для потоковой аналитики, интеграции микросервисов и многого другого.

## Репликация

Репликация - надежность и отказоустойчивость данных, чтобы мы не теряли данные какой-нибудь партиции, введена репликация между брокерами (Set replication-factor)

В Leader реплику попали какие то данные (данные всегда пишутся в лидер реплику), дальше эти события должны попасть в фоловеры

В Kafka используется in-sync-replicas(ISR) - особенность этих реплик в том, что когда мы пишем события в Leader мы сразу же пишем синхронно в ISR Фоловеры, при этом другие Фоловеры опрашивают Leader и могут немного отставать 
