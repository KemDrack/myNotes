
https://debezium.io/documentation/reference/3.0/


[[Transaction Outbox]] + Debezium

Debezium читает данные не через SQL запросы, а из **WAL-журнала**, где хранятся все изменения, перед тем как их применять к табличкам

Если мы удалили запись, то через SQL мы не сможем получить эту запись, а в WAL она будет присутствовать. Плюс чтение WAL не так сильно нагружает систему чем через SQL

По сути это готовое решение, только нужно настроить коннекторы

Из-за Debezium нам не нужно писать Job, нет продюсера, микросервис никак с кафкой не взаимодействует напрямую

Есть 2 топика, топик куда Debezium отправялет данные              (cv-app.public.outbox) и топик(cv-topic) откуда микросервис читает
*Топик outbox*: **id**, **payload**(текстовая строка, json объекта, который нам нужно переслать в кафку), **created_at**, **type**(нужно предусмотреть тип отправляемых данных)
У топика cv-topic данные в другом формате, там уже нету ничего связанного с таблицей outbox, а только сами данные

Преобразование данных из топика куда пишет Debezium в топик из котого читает микросервис занимается **Kafka Streams**

!!!
**Kafka Streams** - микросервис, построенный с помощью кафка стримов. Позволяет создавать приложения для потоковой обработки данных в режиме реального времени. 
Позволяет преобразовывать данные между топиками кафки.
Основная единица в Kafka Streams - поток, непрерывный поток сообщений из топика кафки. И Kafka Streams позволяет выполнять различные операции с потоками(фильтрация, преобразование, объединения, разбиение)
https://github.com/redpanda-data/connect

![[{D650456E-D60E-4B58-9E17-469197E361AE}.png]]


