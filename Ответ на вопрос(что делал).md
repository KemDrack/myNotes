
Если сервисы развернуты на разных физических или виртуальных машинах (нодах), Envoy может выступать в роли централизованного прокси, маршрутизируя запросы между этими нодами

- Каждый сервис запускается на своей ноде с уникальным IP-адресом.
- Envoy балансирует запросы между нодами через их IP.
- При изменении списка нод (например, добавлении нового сервиса) испч

### **Что такое равномерное распределение трафика?**
Равномерное распределение (или балансировка нагрузки) направлено на то, чтобы запросы к сервису распределялись между доступными экземплярами в соответствии с выбранным алгоритмом. В контексте работы с проектом на Go это может включать:

- Балансировку HTTP-запросов между несколькими сервисами.
- A/B-тестирование (распределение трафика между разными версиями одного сервиса).
- Маршрутизацию запросов с учётом метрик или политики (например, 50% на сервис 1 и 50% на сервис 2).

Вот пример, где трафик распределяется между тремя экземплярами сервиса на Go (например, `service1`, `service2` и `service3`).
```yaml
static_resources:
  listeners:
    - name: listener_0
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 10000
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: ingress_http
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: service
                      domains: ["*"]
                      routes:
                        - match:
                            prefix: "/"
                          route:
                            cluster: go_service_cluster
                http_filters:
                  - name: envoy.filters.http.router
  clusters:
    - name: go_service_cluster
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: go_service_cluster
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: service1
                      port_value: 8080
              - endpoint:
                  address:
                    socket_address:
                      address: service2
                      port_value: 8080
              - endpoint:
                  address:
                    socket_address:
                      address: service3
                      port_value: 8080

```
- **Listeners:**
    - Настраивают входной порт Envoy (в данном случае `10000`).
    - Входящий запрос перенаправляется на кластер `go_service_cluster`
- **Clusters:**
    - Кластер объединяет несколько экземпляров бэкенд-сервиса на Go.
    - Указан алгоритм балансировки нагрузки `ROUND_ROBIN` для равномерного распределения запросов.
- **Endpoints:**
    - Описываются IP-адреса или хосты, на которых запущены экземпляры сервиса.
    - Пример: три экземпляра сервиса работают на `service1:8080`, `service2:8080`, и `service3:8080`.
- **Балансировка нагрузки:**
    - `ROUND_ROBIN` циклически распределяет запросы между всеми доступными экземплярами.


### **A/B-тестирование или разделение трафика**

Если у нас есть две версии сервиса (например, `v1` и `v2`), можно настроить распределение трафика, отправляя 50% запросов в одну версию и 50% — в другую.
```yml
clusters:
  - name: go_service_v1
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: go_service_v1
      endpoints:
        - lb_endpoints:
            - endpoint:
                address:
                  socket_address:
                    address: service_v1
                    port_value: 8080

  - name: go_service_v2
    connect_timeout: 0.25s
    type: LOGICAL_DNS
    lb_policy: ROUND_ROBIN
    load_assignment:
      cluster_name: go_service_v2
      endpoints:
        - lb_endpoints:
            - endpoint:
                address:
                  socket_address:
                    address: service_v2
                    port_value: 8081

route_config:
  name: local_route
  virtual_hosts:
    - name: service
      domains: ["*"]
      routes:
        - match:
            prefix: "/"
          route:
            weighted_clusters:
              clusters:
                - name: go_service_v1
                  weight: 50
                - name: go_service_v2
                  weight: 50
```
- **Weighted Clusters:** Позволяет указать веса для распределения трафика.


#### **Добавление метрик и наблюдаемости**
Для анализа работы балансировки добавьте метрики Envoy. Подключите Prometheus для сбора данных о том, сколько запросов отправляется на каждый экземпляр.
```yml
admin:
  access_log_path: "/tmp/envoy_admin_access.log"
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901
```

